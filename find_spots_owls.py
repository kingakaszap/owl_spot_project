# -*- coding: utf-8 -*-
"""find_spots_owls.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yUj3QwHy5vIr7knU2W3HkS3nmfoS56Uy

## **Libraries and data import**

In this section, I first load the required libraries, and then the data. There is also some data inspection going on
"""

### libraries ###
import os
import keras
from keras import ops
import keras_hub
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import random
from PIL import Image
from PIL import ImageOps
import matplotlib
import keras_hub
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import ResNet50
from sklearn.model_selection import KFold
from tensorflow.keras.optimizers import Adam
import re
import datetime

## reproducibility stuff ###
seed = 42
random.seed(seed)
np.random.seed(seed)
tf.random.set_seed(seed)

### import data ###
# previously uploaded to google drive
from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/owls_spots.zip -d /content/owls_spots
# change the structure a bit
# move the 'images' and 'masks' folders up one level
!mv /content/owls_spots/owls_spots/images /content/owls_spots/
!mv /content/owls_spots/owls_spots/masks  /content/owls_spots/

# delete the now empty nested folder
!rm -r /content/owls_spots/owls_spots

# define paths and store, for the images and for the masks (spots)
image_dir = '/content/owls_spots/images'
mask_dir = '/content/owls_spots/masks'

# look at the data and see if all good
image_files = sorted(os.listdir(image_dir))
mask_files = sorted(os.listdir(mask_dir))
# take a list of filenames in the 2 folders and sort them alphabetically
assert len(image_files) == len(mask_files), "something is off"
mask_example_path = '/content/owls_spots/masks/891942_Belly_IMG_8931.png'
mask_example = Image.open(mask_example_path)
print(mask_example.mode)  # grayscale
print(np.array(mask_example).shape)  # height & width, no nr of channels bc its grayscale

### Get body parts ### --- later removed the part where this was used, but this would be for stratified cval. Still nice to have an idea
possible_bodyparts = ['Back', 'Belly', 'Flank',  'Wing']
body_parts = []
for filename in image_files:
    match = [bp for bp in possible_bodyparts if bp in filename]
    if match:
        body_parts.append(match[0])  # take first match (should be the only match)
    else:
        body_parts.append('unknown')  # fallback if no body part found - should not happen

body_parts = np.array(body_parts)
print(body_parts[:30])
# ok seems good

# values of masks. know that they are grayscale but what values
mask = Image.open(mask_example_path).convert('L')
mask_array = np.array(mask)
unique_values_masks = np.unique(mask_array)

print(f": {mask_example_path} has grayscale values between 0 and 255:", unique_values_masks)
# not ideal - we need 0 (background, black) vs 1 (for the spot) --- i hope --- fix later

# visualise one mask
img_mask_example = matplotlib.image.imread(mask_example_path)

plt.imshow(img_mask_example, cmap = "gray")
plt.axis('off')
plt.show()

# also look at the images
image_example_path = '/content/owls_spots/images/891942_Belly_IMG_8931.jpg'
image_example = Image.open(image_example_path)
print(image_example.mode)  # rgb
print(np.array(image_example).shape)  # number of channels + rgb = 3
# visualise
img_example = matplotlib.image.imread(image_example_path)

plt.imshow(img_example)
plt.axis('off')
plt.show() # cute

"""## **Paddding**

For a CNN to work, input images need to be in the same dimensions (as well as masks). Since my original images are various dimensions, need to apply padding to fix that.
"""

### step 1 - padding to ensure images have the same dims ####
# set target dims for cnn
target_height = 256
target_width = 256

""" macth images and masks by filename

 by doing a dictionary where key = basename of both mask&img;  file = mask file
"""

mask_dict = {os.path.splitext(f)[0]: f for f in os.listdir(mask_dir)}
# os.listdir(mask_dir): list all filenames in masks directory
# os.path.splitext(f) - split files to basename and the extensions. -> tuple like (basename, .extension)
# [0] - refer to 1st element of the tuple: basename
# for each f (element) in the masks directory, take the basename as key, and the element itself is the value (key:value for x in y)
# key: basename, value: element

# padding
images_resized = [] # now list but in the end want np arrays
masks_resized = []

for img_file in os.listdir(image_dir):
# take an image
  key = os.path.splitext(img_file)[0] # filename, no extension (1st element of split tuple), should be
# identical for mask and img.
  if key not in mask_dict:
    print(f"warning!!! no mask for {img_file}")
    continue
  # but if this happens it is an issue, should not happen

  mask_file = mask_dict[key] # get the corresponding mask file to this image

# now checked if all images have masks and paired them

# load, pad images
  img = Image.open(os.path.join(image_dir, img_file)).convert('RGB')
  img = ImageOps.pad(img, (target_height, target_width))
  images_resized.append(np.array(img))
  # add the image as a np array to the list

# load, pad mask
  mask = Image.open(os.path.join(mask_dir, mask_file)).convert('L') # grayscale: 0 is black, 255 is white
  mask = ImageOps.pad(mask, (target_height, target_width))
  mask_array = np.array(mask)

# binarize mask: 0 is background, 1 is spot
  mask_array = (mask_array >0).astype(np.uint8)
  # compare every pixel to 0. if 0 black if >0 then white. convert true/false to 1/0
  # i hope this is ok but background did look quite black in pic
  masks_resized.append(mask_array)

images = np.array(images_resized)
masks = np.array(masks_resized)

print("images shape", images.shape, "masks shape", masks.shape)

"""Okay fab let's see if all looks good"""

# look at some of the images and their corresponding masks
num_to_show = 5
indices = random.sample(range(len(images)), num_to_show)  # pick 5 random indices

plt.figure(figsize=(12, 5))

for i, idx in enumerate(indices): # i: count 0-4; idx: actual index in the indices
    # original image
    plt.subplot(2, num_to_show, i+1) # grid: 2 rows, 5 cols; position: i+1 (zero based indexing but matplot starts from 1)
    plt.imshow(images[idx].astype(np.uint8))
    plt.axis('off')
    if i == 2:
        plt.title("Original Images (padded)")

    # corresponding mask
    plt.subplot(2, num_to_show, i+1+num_to_show)
    plt.imshow(masks[idx], cmap='gray')
    plt.axis('off')
    if i == 2:
        plt.title("Masks (binarized & padded)")

plt.tight_layout()
plt.show()

"""## **Define functions for data augmentation**

Goal is to have a relative aggressive augmentation pipeline, as I saw that models are very prone to overfitting the training set.

Important Points


*   if doing k-fold cval, augmentation should be applied on the go and after the folds, as only need to augment trainng set
*   need to apply the exact same transformation to an image and its mask (in most cases. sometimes mask stays unchanged)
*   augmentation only on the training set, NOT on test set and NOT on val set
*   interpolation - don't fully understand but something like: needed because when rotate, the new rotated pixels dont align perfectly anymore with the original grid BUT at default interpolation creates fractional values -- we dont want this for masks as mask values are 0 / 1(background/spot)  so this would  break segmentation labels ---#  so use two generators, different for mask and for image. use nearest neighbor for mask
"""

## define a function for data augmentation, compatible with tf
def augment_image_mask(image, mask,
                       max_shift=5,
                       zoom_range=(1.0,1.2),
                       max_brightness=0.2,
                       max_contrast=0.2,
                       noise_std=0.05):
    h = tf.shape(image)[0]
    w = tf.shape(image)[1]

    # --- geometric transforms (applied to both image and mask) ---

    # random horizontal flip
    if tf.random.uniform([]) > 0.5:
        image = tf.image.flip_left_right(image)
        mask  = tf.image.flip_left_right(mask)
    # and vertical
    if tf.random.uniform([]) > 0.5:
        image = tf.image.flip_up_down(image)
        mask  = tf.image.flip_up_down(mask)
   # small shift
    dx = tf.random.uniform([], -max_shift, max_shift+1, dtype=tf.int32)
    dy = tf.random.uniform([], -max_shift, max_shift+1, dtype=tf.int32)
    image = tf.roll(image, shift=[dy, dx], axis=[0,1])
    mask  = tf.roll(mask, shift=[dy, dx], axis=[0,1])

    # zoom in only - maybe remove? images usually similar sizes
    zoom = tf.random.uniform([], zoom_range[0], zoom_range[1])
    new_h = tf.cast(tf.cast(h, tf.float32) * zoom, tf.int32)
    new_w = tf.cast(tf.cast(w, tf.float32) * zoom, tf.int32)
    image = tf.image.resize(image, [new_h, new_w], method='bilinear')
    mask  = tf.image.resize(mask,  [new_h, new_w], method='nearest')
    image = tf.image.resize_with_crop_or_pad(image, h, w)
    mask  = tf.image.resize_with_crop_or_pad(mask, h, w)

    # random rotation
    k = tf.random.uniform([], 0, 4, dtype=tf.int32)
    image = tf.image.rot90(image, k)
    mask  = tf.image.rot90(mask, k)

    # photometric transforms - change brightness and contrast (image only)
    # and noise
    image = tf.image.random_brightness(image, max_delta=max_brightness)
    image = tf.image.random_contrast(image, 1-max_contrast, 1+max_contrast)
    image += tf.random.normal(tf.shape(image), mean=0.0, stddev=noise_std)

    # Ensure mask stays binary
    mask = tf.round(mask)

    return image, mask

def preprocess_training_set(image, mask):
    # normalize
    image = tf.image.convert_image_dtype(image, tf.float32) # tf-s own normalisation command (?)
    mask  = tf.cast(mask > 0, tf.float32) # and also binarise masks
    # apply augmentations
    image, mask = augment_image_mask(image, mask)
    return image, mask

# try to fix  error - smth with test dataset size
def preprocess_test_set(image, mask):
    # normalize
    image = tf.image.convert_image_dtype(image, tf.float32)
    mask  = tf.cast(mask > 0 , tf.float32)
# mask should be binary, 0 or 1
    # ensure shape will be ok this time
    image.set_shape([256, 256, 3])
    mask.set_shape([256, 256, 1])

    return image, mask

"""Look at a few augmented examples"""

print(images.dtype, images.min(), images.max())

def preprocess_training_set_viz(image, mask): # troubleshooting bc they looked WEIRD
    # same as  real preprocess function
    image = tf.image.convert_image_dtype(image, tf.float32)
    mask  = tf.cast(mask > 0, tf.float32)

    image, mask = augment_image_mask(image, mask)

    # EXTRA STEP ONLY FOR VISUALISATION:
    # clip values after brightness/contrast/noise
    image = tf.clip_by_value(image, 0.0, 1.0)

    return image, mask

import matplotlib.gridspec as gridspec

images_viz = images.astype(np.uint8)
masks_viz = np.expand_dims(masks, axis=-1).astype(np.uint8)

visualise_augmentation_ds = (tf.data.Dataset.from_tensor_slices((images_viz, masks_viz))
    .map(preprocess_training_set_viz)
    .take(5))

plt.figure(figsize=(6, 15))
plt.suptitle("Augmented images and corresponding masks", fontsize=16)

for i, (img, msk) in enumerate(visualise_augmentation_ds):
    img = img.numpy()
    msk = msk.numpy().squeeze()

    # Image subplot
    plt.subplot(5, 2, 2*i + 1)
    plt.imshow(img)
    plt.axis("off")
    if i == 0:
        plt.title("Images", fontsize=12)

    # Mask subplot below
    plt.subplot(5, 2, 2*i + 2)
    plt.imshow(msk, cmap="gray")
    plt.axis("off")
    if i == 0:
        plt.title("Masks", fontsize=12)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""## **Define functions for model and loss**

## **U-net with pre-trained ResNet encoder**

The first u-net architecture with using transfer learning.
"""

def unet_resnet_encoder(input_shape=(256, 256, 3)): # ie images
    # --- encoder: pretrained ResNet50 ---
    # (feature extractor)
    base_model = ResNet50(include_top=False,weights='imagenet', # learned on many many images
        input_shape=input_shape)

    # select layers for skip connections (ie between down part of u and upward part of u)
    skip_names = [
        # reducing resolution in resnet with these layers
        # but also "passing on" the info to the upsampling path - so that details are not lost ?
        'conv1_relu',       # 128x128
        'conv2_block3_out', # 64x64
        'conv3_block4_out', # 32x32
        'conv4_block6_out'  # 16x16
    ] # recommended by ai
    skip_outputs = [base_model.get_layer(name).output for name in skip_names]

    x = base_model.output # 8x8 features in resnet THIS IS THE BOTTLENECK here we have many many filters

    # decoder
    filters = [512, 256, 128, 64]  # number of filters for each upsampling block
    for i in range(4):
        x = layers.Conv2DTranspose(filters[i], 3, strides=2, padding='same', activation='relu')(x)
        x = layers.Concatenate()([x, skip_outputs[3 - i]])  # reverse order
        x = layers.Conv2D(filters[i], 3, padding='same', activation='relu')(x)
        x = layers.Conv2D(filters[i], 3, padding='same', activation='relu')(x)

    # final upsampling to 256x256
    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)
    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)

    # output layer - sigmoid mask
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x) # probability, spot vs not spot
    model = Model(inputs=base_model.input, outputs=outputs)
    return model

"""## **"simple" unet with no transfer learning**

The second u-net architecture trained from scratch.

- uses dropout for regulariaztion
- maxpool for downsampling (not the stride thing)
- reaches way fewer filters than resnet
"""

# try to define a simple ish model without transfer learning

def simple_unet(input_shape=(256, 256, 3), dropout_rate=0.2): # to reduce overfitting
    inputs = layers.Input(shape=input_shape)

    # --- Encoder ---
    # Block 1
    x1 = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)
    x1 = layers.BatchNormalization()(x1)
    x1 = layers.Conv2D(32, 3, padding='same', activation='relu')(x1)
    x1 = layers.BatchNormalization()(x1)
    p1 = layers.MaxPooling2D(2)(x1)

    # Block 2
    x2 = layers.Conv2D(64, 3, padding='same', activation='relu')(p1)
    x2 = layers.BatchNormalization()(x2)
    x2 = layers.Conv2D(64, 3, padding='same', activation='relu')(x2)
    x2 = layers.BatchNormalization()(x2)
    p2 = layers.MaxPooling2D(2)(x2)

    # Block 3 (bottleneck)
    x3 = layers.Conv2D(128, 3, padding='same', activation='relu')(p2)
    x3 = layers.BatchNormalization()(x3)
    x3 = layers.Conv2D(128, 3, padding='same', activation='relu')(x3)
    x3 = layers.BatchNormalization()(x3)
    x3 = layers.Dropout(dropout_rate)(x3)

    # --- Decoder ---
    # Up 1
    u1 = layers.Conv2DTranspose(64, 2, strides=2, padding='same', activation='relu')(x3)
    u1 = layers.Concatenate()([u1, x2]) # skip connection
    u1 = layers.Conv2D(64, 3, padding='same', activation='relu')(u1)
    u1 = layers.BatchNormalization()(u1)
    u1 = layers.Conv2D(64, 3, padding='same', activation='relu')(u1)
    u1 = layers.BatchNormalization()(u1)
    u1 = layers.Dropout(dropout_rate)(u1)

    # Up 2
    u2 = layers.Conv2DTranspose(32, 2, strides=2, padding='same', activation='relu')(u1)
    u2 = layers.Concatenate()([u2, x1]) # skip connection
    u2 = layers.Conv2D(32, 3, padding='same', activation='relu')(u2)
    u2 = layers.BatchNormalization()(u2)
    u2 = layers.Conv2D(32, 3, padding='same', activation='relu')(u2)
    u2 = layers.BatchNormalization()(u2)
    u2 = layers.Dropout(dropout_rate)(u2)

    # output layer - as before, sigmoid mask
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(u2)

    model = Model(inputs=inputs, outputs=outputs)
    return model

"""## **Define loss functions and performance metrics**

Define the loss functions and the metrics for evaluating model performances that will be used.
"""

# Dice loss - better for disproportionate datasets --- but was unstable alone
# potentially combine dice loss with BCE? chatgpt recommended, maybe, lets see later if it improves model

# dice coefficient but in a more chill (smooth) way
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# define Dice loss --- aalso smoother
def dice_loss(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# combined loss - eventually decided to use this version
bce_loss = tf.keras.losses.BinaryCrossentropy()
def combined_loss(y_true, y_pred, bce_weight=0.05):
    return dice_loss(y_true, y_pred) + bce_weight * bce_loss(y_true, y_pred)

# loss is just just 1-dice coef, 1 dice coef is perfect.

# trying to save model from collapsing

# finally DID NOT USE this loss but the weighted one
def bce_dice_loss(y_true, y_pred): # loss that measures both bce and dice.
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return bce + dice

# wrap the already defined dice coef in a tf.keras.metrics.Metric
class DiceMetric(tf.keras.metrics.Metric):
    def __init__(self, name="dice_coef", **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight(name="total", initializer="zeros")
        self.count = self.add_weight(name="count", initializer="zeros")

    def update_state(self, y_true, y_pred, sample_weight=None):
        dice = dice_coef(y_true, y_pred)
        self.total.assign_add(dice)
        self.count.assign_add(1.0)

    def result(self):
        return self.total / self.count

    def reset_state(self):
        self.total.assign(0.0)
        self.count.assign(0.0)

"""Function for visualising images and masks during training (to see if they are still all predicted as black :'("""

import matplotlib.pyplot as plt

def visualize_predictions(model, dataset, num_images=3):

    # take one batch (or iterate through)
    for images, masks in dataset.take(1):
        preds = model.predict(images)
        preds = (preds > 0.5).astype(np.float32)  # binarize predictions

        for i in range(min(num_images, images.shape[0])):
            fig, axes = plt.subplots(1, 3, figsize=(12, 4))
            axes[0].imshow(images[i])
            axes[0].set_title("Original image")
            axes[0].axis('off')

            axes[1].imshow(masks[i,:,:,0], cmap='gray')
            axes[1].set_title("True mask")
            axes[1].axis('off')

            axes[2].imshow(preds[i,:,:,0], cmap='gray')
            axes[2].set_title("Predicted mask")
            axes[2].axis('off')

            plt.show()

"""## **Split into training, validation and test set**"""

# tf compatible format
images_tf = images.astype(np.float32) / 255.0       # (N, H, W, 3) # normalize !
# convert masks to binary 0 or 1
masks_tf = (masks > 0).astype(np.float32)[..., np.newaxis]

(train_images, test_images,
 train_masks,  test_masks,
 train_parts,  test_parts) = train_test_split( # not used this stratification criteria in final models
    images_tf, masks_tf, body_parts,
    test_size=0.1, random_state=42, stratify=body_parts)

# body parts included so that i can see where they ended up in the splits later
# original dataset (always keep these)
dataset_orig = tf.data.Dataset.from_tensor_slices((images_tf, masks_tf))

# how many?
print("train_images:", train_images.shape[0])
print("train_masks:", train_masks.shape[0])
print("train_parts:", train_parts.shape[0])

print("mask min value:", train_masks.min(), "mask max value:", train_masks.max())
# sanity check as masks were still 0-255 at some point which i dont want

print(train_images.shape)
print(train_masks.shape)
print(test_images.shape)
print(test_masks.shape)
print(train_parts.shape)
print(test_parts.shape)
# um not sure about these last 2

# sanity check
### QUICK SANITY CHECK FOR IMAGES + MASKS ###
# use only in the later bad models

def quick_dataset_check(ds, name="dataset"):
    one_batch = next(iter(ds.take(1)))
    imgs, masks = one_batch

    print(f"\n--- sanity check for {name} ---")

    print(" images:   min =", float(tf.reduce_min(imgs)),
          " max =", float(tf.reduce_max(imgs)),
          " mean =", float(tf.reduce_mean(imgs)))

    print(" masks:    min =", float(tf.reduce_min(masks)),
          " max =", float(tf.reduce_max(masks)),
          " mean =", float(tf.reduce_mean(masks)))

    # count positive mask pixels
    pos = tf.reduce_sum(masks).numpy()
    print(" total positive mask pixels in batch =", pos)

    # verify binary (0 or 1)
    unique = tf.unique(tf.reshape(masks, [-1]))[0].numpy()
    print(" mask unique values:", unique)

    if pos == 0:
        print(" WARNING: batch mask is ALL ZERO (no positive pixels).")

    # check shapes
    print(" image batch shape:", imgs.shape)
    print(" mask batch shape:", masks.shape)
    print("--- end of sanity check ---\n")

"""## **Fit simple u-net, no augment**"""

# WITH A VALIDATION SET
train_images_small, val_images_small, train_masks_small, val_masks_small = train_test_split(
    train_images,train_masks,
    test_size=0.1,
    random_state=42)

# fit without data augmentation
train_dataset_noaug = tf.data.Dataset.from_tensor_slices((train_images_small, train_masks_small))
val_dataset_noaug   = tf.data.Dataset.from_tensor_slices((val_images_small, val_masks_small))
test_dataset_noaug  = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

train_dataset_noaug =(train_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .shuffle(500, seed = seed)
    .batch(8)
    .prefetch(1))

val_dataset_noaug = (val_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE) # ie no aug
    .batch(8)
    .prefetch(1))

# test dataset (no augmentation)
test_dataset_noaug = (test_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(1))

# logs
log_dir_noaug = "logs/noaug_scratch_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb_noaug = tf.keras.callbacks.TensorBoard(log_dir=log_dir_noaug,
    histogram_freq=1,
    write_graph=False)

model_scratch_noaug = simple_unet(input_shape=(256, 256, 3))
binaryiou = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")
dice = DiceMetric()
model_scratch_noaug.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='binary_crossentropy',
    metrics=[dice,binaryiou])
history_noaug_scratch = model_scratch_noaug.fit(
    train_dataset_noaug,
    validation_data=val_dataset_noaug,
    callbacks=[tensorboard_cb_noaug],
    epochs=10)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

results_simplest = model_scratch_noaug.evaluate(test_dataset_noaug)
print("performance:", results_simplest)

# get predictions for a batch from the test dataset
for images_batch, masks_batch in test_dataset_noaug.take(1):
    preds = model_scratch_noaug.predict(images_batch)
    # Convert probabilities to binary masks
    preds_binary = (preds > 0.5).astype("float32")

import matplotlib.pyplot as plt

batch_size = images_batch.shape[0]
plt.figure(figsize=(12, 6))

for i in range(min(batch_size, 5)):
    # original image
    plt.subplot(3, 5, i+1)
    plt.imshow(images_batch[i].numpy())
    plt.axis('off')
    if i == 0: plt.title("Image")

    # ground truth mask
    plt.subplot(3, 5, i+1+5)
    plt.imshow(masks_batch[i].numpy().squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Mask")

    # predicted mask
    plt.subplot(3, 5, i+1+10)
    plt.imshow(preds_binary[i].squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Predicted")

plt.tight_layout()
plt.show()

"""Can conclude that this is not an ideal result.

## **Fit simple unet but with augmentation**
"""

print(len(train_images_small), len(val_images_small), len(test_images))
# split was a little bit off as i did the 0.1 split only from the train images so test set is a bit bigger.
# but only two images dif so i won't worry about it. its just 1 image that should be in val set thats now in test set. oh well.

# original (unaugmented) datasets
train_dataset_easy = tf.data.Dataset.from_tensor_slices((train_images_small, train_masks_small))
val_dataset_easy   = tf.data.Dataset.from_tensor_slices((val_images_small, val_masks_small))
test_dataset_easy  = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

# augment the training data (5x)
train_dataset_easy_aug = (train_dataset_easy
    .repeat(5)
    .map(preprocess_training_set, num_parallel_calls=tf.data.AUTOTUNE))

# combine original + augmented for training
train_dataset_full_easy = (train_dataset_easy
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .concatenate(train_dataset_easy_aug) # so have 1x original and 5x augmented dataset
    .shuffle(500, seed = seed)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

val_dataset_easy = (val_dataset_easy  # no aug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

# test dataset (no augmentation)
test_dataset_easy = (test_dataset_easy
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

# logs
log_dir_aug_scratch = "logs/aug_scratch_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb_aug_scratch = tf.keras.callbacks.TensorBoard(log_dir=log_dir_aug_scratch,
    histogram_freq=1,
    write_graph=False)

model_scratch = simple_unet(input_shape=(256, 256, 3))

binaryiou = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")
dice = DiceMetric()
model_scratch.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='binary_crossentropy',
    # change to dice loss, but no built in function for that
     metrics=[dice,binaryiou])

history_scratch = model_scratch.fit(train_dataset_full_easy,
    validation_data=val_dataset_easy,
    callbacks = [tensorboard_cb_aug_scratch],
    epochs=10)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

results_scratch_model = model_scratch.evaluate(test_dataset_easy)
print("Test loss and performance:", results_scratch_model)

# get predictions for a batch from the test dataset
for images_batch, masks_batch in test_dataset_easy.take(2):
    preds = model_scratch.predict(images_batch)
    # Convert probabilities to binary masks
    preds_binary = (preds > 0.5).astype("float32")

batch_size = images_batch.shape[0]
plt.figure(figsize=(12, 6))

for i in range(min(batch_size, 5)):
    # original image
    plt.subplot(3, 5, i+1)
    plt.imshow(images_batch[i].numpy())
    plt.axis('off')
    if i == 0: plt.title("Image")

    # ground truth mask
    plt.subplot(3, 5, i+1+5)
    plt.imshow(masks_batch[i].numpy().squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Mask")

    # predicted mask
    plt.subplot(3, 5, i+1+10)
    plt.imshow(preds_binary[i].squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Predicted")

plt.tight_layout()
plt.show()

"""## **Fit pre-trained unet, no augment**"""

# fit without data augmentation
# Original (unaugmented) datasets - might not have to do this again idk
train_dataset_noaug = tf.data.Dataset.from_tensor_slices((train_images_small, train_masks_small))
val_dataset_noaug   = tf.data.Dataset.from_tensor_slices((val_images_small, val_masks_small))
test_dataset_noaug  = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

train_dataset_noaug =(train_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .shuffle(500, seed = seed)
    .batch(8)
    .prefetch(1))

val_dataset_noaug = (val_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(1))

# test dataset (no augmentation)
test_dataset_noaug = (test_dataset_noaug
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(1))

# logs
log_dir_noaug_resnet = "logs/noaug_resnet_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb_noaug_resnet = tf.keras.callbacks.TensorBoard(log_dir=log_dir_noaug_resnet,
    histogram_freq=1,
    write_graph=False)

model_noaug = unet_resnet_encoder(input_shape=(256, 256, 3))
binaryiou = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")
dice = DiceMetric()
model_noaug.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='binary_crossentropy',
    metrics=[dice,binaryiou])
history_noaug = model_noaug.fit(train_dataset_noaug,
    callbacks = [tensorboard_cb_noaug_resnet],
    validation_data=val_dataset_noaug,
    epochs=10)

results_simple_model = model_noaug.evaluate(test_dataset_noaug)
print("performance:", results_simple_model)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

# get predictions for a batch from the test dataset
for images_batch, masks_batch in test_dataset_noaug.take(1):
    preds = model_noaug.predict(images_batch)
    # convert probabilities to binary masks
    preds_binary = (preds > 0.5).astype("float32")

batch_size = images_batch.shape[0]
plt.figure(figsize=(12, 6))

for i in range(min(batch_size, 5)):
    # original image
    plt.subplot(3, 5, i+1)
    plt.imshow(images_batch[i].numpy())
    plt.axis('off')
    if i == 0: plt.title("Image")

    # ground truth mask
    plt.subplot(3, 5, i+1+5)
    plt.imshow(masks_batch[i].numpy().squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Mask")

    # predicted mask
    plt.subplot(3, 5, i+1+10)
    plt.imshow(preds_binary[i].squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Predicted")

plt.tight_layout()
plt.show()

"""again does not look extremely promising at predicting spots :')

##**Fit pre-trained unet with augmentation**
"""

log_dir_aug_resnet = "logs/aug_resnet_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb_aug_resnet = tf.keras.callbacks.TensorBoard(log_dir=log_dir_aug_resnet,
    histogram_freq=1,
    write_graph=False)

# original (unaugmented) datasets
train_dataset_easy = tf.data.Dataset.from_tensor_slices((train_images_small, train_masks_small))
val_dataset_easy   = tf.data.Dataset.from_tensor_slices((val_images_small, val_masks_small))
test_dataset_easy  = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

# augment the training data (5x)
train_dataset_easy_aug = (train_dataset_easy
    .repeat(5)
    .map(preprocess_training_set, num_parallel_calls=tf.data.AUTOTUNE))

# combine original + augmented for training
train_dataset_full_easy = (train_dataset_easy
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .concatenate(train_dataset_easy_aug) # so have 1x original and 5x augmented dataset
    .shuffle(500, seed = seed)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

val_dataset_easy = (val_dataset_easy
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

# test dataset (no augmentation)
test_dataset_easy = (test_dataset_easy
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE))

model_easy = unet_resnet_encoder(input_shape=(256, 256, 3))

binaryiou = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")
dice = DiceMetric()
model_easy.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='binary_crossentropy',
     metrics=[dice,binaryiou])

history_easy = model_easy.fit(train_dataset_full_easy,
    callbacks = [tensorboard_cb_aug_resnet],
    validation_data=val_dataset_easy,
    epochs=10)

results_simple_model = model_easy.evaluate(test_dataset_easy)
print("performance:", results_simple_model)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

# get predictions for a batch from the test dataset
for images_batch, masks_batch in test_dataset_easy.take(1):
    preds = model_easy.predict(images_batch)
    # Convert probabilities to binary masks
    preds_binary = (preds > 0.5).astype("float32")

import matplotlib.pyplot as plt

batch_size = images_batch.shape[0]
plt.figure(figsize=(12, 6))

for i in range(min(batch_size, 5)):
    # original image
    plt.subplot(3, 5, i+1)
    plt.imshow(images_batch[i].numpy())
    plt.axis('off')
    if i == 0: plt.title("Image")

    # ground truth mask
    plt.subplot(3, 5, i+1+5)
    plt.imshow(masks_batch[i].numpy().squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Mask")

    # predicted mask
    plt.subplot(3, 5, i+1+10)
    plt.imshow(preds_binary[i].squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Predicted")

plt.tight_layout()
plt.show()

"""looks good

## **Hyperparameter search on best performing model**

i.e. the last one; pre-trained unet with augmentation. hyperparameters being tuned are learning rate and loss function.
"""

# Directory where all runs will be stored
log_root = "logs/hparam_search"
os.makedirs(log_root, exist_ok=True)

# hyperparameters to test
hyperparameters = [{"lr": 1e-4,  "loss": "binary_crossentropy"},
    {"lr": 1e-4,  "loss": "dice"},
    {"lr": 0.001, "loss": "binary_crossentropy"},
    {"lr": 0.001, "loss": "dice"},]

batch_size = 8
results = []

# original (unaugmented) datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_small, train_masks_small))
val_dataset  = tf.data.Dataset.from_tensor_slices((val_images_small, val_masks_small))

# Augment the training data (5x)
train_dataset_aug = (train_dataset
    .repeat(5)
    .map(preprocess_training_set, num_parallel_calls=tf.data.AUTOTUNE))

# combine original + augmented
train_dataset_full = (train_dataset
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .concatenate(train_dataset_aug)
    .shuffle(500, seed = seed)
    .batch(batch_size)
    .prefetch(1)
    # .prefetch(tf.data.AUTOTUNE)
    )

val_dataset = (val_dataset
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1))


for combo in hyperparameters:
    print("\nTesting hyperparameter combination:", combo)

    tf.keras.backend.clear_session()
    model = unet_resnet_encoder(input_shape=(256, 256, 3))

    # select loss from hyperparams
    if combo["loss"] == "dice":
        loss_fn = combined_loss # so has a small bce in it too
    else:
        loss_fn = combo["loss"] # ie bce

    optimiser = tf.keras.optimizers.Adam(learning_rate=combo["lr"])

    binaryiou = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")
    dice = DiceMetric()

    model.compile(optimizer=optimiser, loss=loss_fn, metrics=[dice,binaryiou])

    # quick sanity check
    for img, mask in train_dataset_full.take(1):
        print("Image min/max:", tf.reduce_min(img).numpy(), tf.reduce_max(img).numpy())
        print("Mask min/max:", tf.reduce_min(mask).numpy(), tf.reduce_max(mask).numpy())

    # make unique log dir for this combo
    run_name = f"lr_{combo['lr']}_loss_{combo['loss']}_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}"
    log_dir = os.path.join(log_root, run_name)

    tensorboard_cb = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir,
        histogram_freq=1,
        write_graph=False)

    history = model.fit(
        train_dataset_full,
        callbacks = [tensorboard_cb],
        validation_data=val_dataset,
        epochs=10,  # the more epochs the better, first 6-7 useless for val dice.
        verbose=1)

    best_val_dice = max(history.history["val_dice_coef"])
    results.append({**combo, "best_val_dice_coef": best_val_dice})
    print(f"Best dice for combo: {best_val_dice:.4f}")

    visualize_predictions(model, val_dataset, num_images=3)

print("\nhyperparameter search results:")
for r in results:
    print(r)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs/hparam_search

"""##  **final model**

we now have 1) the ideal architecture (unet with pre-trained resnet encoder, and data augmentation) and 2) the ideal hyperparameters. Now we fit this '''"perfect''' model on the combined training and validation set, and evaluate its performance on the test set
"""

tf.keras.backend.clear_session()

# Combine train + validation
full_train_images = np.concatenate([train_images_small, val_images_small], axis=0)
full_train_masks  = np.concatenate([train_masks_small, val_masks_small], axis=0)

# logs
log_dir_final = "logs/final_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb_final = tf.keras.callbacks.TensorBoard(log_dir=log_dir_final,
    histogram_freq=1,
    write_graph=False)

# Original dataset
batch_size = 8
full_train_dataset = tf.data.Dataset.from_tensor_slices((full_train_images, full_train_masks))

# augmentation (same as before)
full_train_dataset_aug = (full_train_dataset
    .repeat(5)
    .map(preprocess_training_set, num_parallel_calls=tf.data.AUTOTUNE))

# Combine original + augmented
full_train_dataset = (
    full_train_dataset
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .concatenate(full_train_dataset_aug)
    .shuffle(500, seed=42)
    .batch(batch_size)
    .prefetch(1))

# test dataset (no augmentation)
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks))
test_dataset = (
    test_dataset
    .map(preprocess_test_set, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1))

tf.keras.backend.clear_session()
model = unet_resnet_encoder(input_shape=(256, 256, 3))

loss_fn = combined_loss  # because 'dice' was best
optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)

# metrics
dice_metric = DiceMetric()
binary_iou_metric = tf.keras.metrics.BinaryIoU(threshold=0.5, name="binary_iou")

model.compile(optimizer=optimiser, loss=loss_fn, metrics=[dice_metric, binary_iou_metric])

history = model.fit(full_train_dataset,
                    callbacks = [tensorboard_cb_final],
    epochs=20,
    verbose=1)

test_results = model.evaluate(test_dataset)
print("Test results (loss, dice, binary_iou):", test_results)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs/

# shuffle the test dataset and take 2 batch
for images_batch, masks_batch in test_dataset.shuffle(500).take(2):
    preds = model.predict(images_batch)
    preds_binary = (preds > 0.5).astype("float32")

batch_size = images_batch.shape[0]
plt.figure(figsize=(12, 6))

for i in range(min(batch_size, 5)):
    # original image
    plt.subplot(3, 5, i+1)
    plt.imshow(images_batch[i].numpy())
    plt.axis('off')
    if i == 0: plt.title("Image")

    # ground truth mask
    plt.subplot(3, 5, i+1+5)
    plt.imshow(masks_batch[i].numpy().squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Mask")

    # predicted mask
    plt.subplot(3, 5, i+1+10)
    plt.imshow(preds_binary[i].squeeze(), cmap='gray')
    plt.axis('off')
    if i == 0: plt.title("Predicted")

plt.tight_layout()
plt.show()

"""Some underprediction on images which don't have many spots, but I'll take it."""